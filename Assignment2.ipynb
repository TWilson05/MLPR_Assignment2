{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "data = np.load('DATA/ct_data.npz')\n",
    "X_train = data['X_train']; X_val = data['X_val']; X_test = data['X_test']\n",
    "y_train = data['y_train']; y_val = data['y_val']; y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40754, 384)\n",
      "y_train shape: (40754,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean on y_train is -0.0.\n",
      "The mean in y_val is -0.21600851 +/- 0.01290338.\n",
      "The mean on the first 5785 entries in y_train is -0.44247688 +/- 0.01192627.\n"
     ]
    }
   ],
   "source": [
    "#defining a function to calculate standard error\n",
    "def cal_se(data):\n",
    "    std = np.std(data)\n",
    "    se = std/ (len(data)**(1/2))\n",
    "    return se\n",
    "\n",
    "#verifying the mean on the training set is zero\n",
    "print(f'The mean on y_train is {round(np.mean(y_train), 8)}.')\n",
    "print(f'The mean in y_val is {round(np.mean(y_val),8)} +/- {round(cal_se(y_val), 8)}.')\n",
    "\n",
    "print(f'The mean on the first 5785 entries in y_train is {round(np.mean(y_train[:5785]), 8)} +/- {round(cal_se(y_train[:5785]),8)}.')\n",
    "#used 8 decimal places as that is the pattern of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard errors on the mean values of the first 5785 entries of training and the validation dataset suggest that even the edge cases of the mean of the two sets does not meet the overal population mean values. The standard error bars are misleading here because they do not align to what the population mean is??? \n",
    "\n",
    "standard error --> makes it look like we are more certain than we are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 373) (5785, 373) (6961, 373)\n",
      "constant columns: [ 59  69 179 189 351]\n",
      "duplicate columns: [ 69  78  79 179 188 189 199 287 351 359]\n"
     ]
    }
   ],
   "source": [
    "isConstant = []\n",
    "isDuplicates = np.array(np.zeros(X_train.shape[1]), dtype='bool') \n",
    "\n",
    "#identify all the constant columns\n",
    "for i in range(X_train.shape[1]) :\n",
    "    isConstant.append((X_train[:,i] == X_train[0][i]).all())\n",
    "\n",
    "#identify all the columns which are duplicates to previous columns\n",
    "for i in range(X_train.shape[1]) :\n",
    "    for k in range(i+1, X_train.shape[1]) :\n",
    "        if isDuplicates[k] == False:\n",
    "            isDuplicates[k] = (X_train[:,i] == X_train[:,k]).all()\n",
    "\n",
    "#create a list with all the columns to remove\n",
    "columns_to_remove = np.unique(np.hstack((np.nonzero(isDuplicates)[0], np.nonzero(isConstant)[0])))\n",
    "\n",
    "#remove these columns and name them modified datasets\n",
    "X_train = np.delete(X_train, columns_to_remove ,1)\n",
    "X_val = np.delete(X_val, columns_to_remove ,1)\n",
    "X_test = np.delete(X_test, columns_to_remove ,1)\n",
    "\n",
    "#check if the shape still aligns to expectations (number of rows stay the same, number of columns are same for all three sets)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "# print list of removed columns\n",
    "print(f'constant columns: {np.nonzero(isConstant)[0]}')\n",
    "print(f'duplicate columns: {np.nonzero(isDuplicates)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to set up the following matrix equation to solve for the weights and bias of the linear regression model.\n",
    "$$ \\tilde{\\Phi}=\\left[\\begin{matrix} X_{N\\times D} & 1_{N\\times 1}\\\\ \\sqrt{\\alpha}\\mathbb{I}_{D\\times D} & 0_{D\\times 1} \\end{matrix}\\right],\\quad \\underline{\\tilde{w}}=\\left[\\begin{matrix} w_{D\\times 1}\\\\ b\\end{matrix}\\right],\\quad \\underline{\\tilde{y}}=\\left[\\begin{matrix} y_{D\\times 1}\\\\ 0\\end{matrix}\\right] $$\n",
    "$$ E(\\underline{w},b)=(\\tilde{\\Phi}\\underline{\\tilde{w}}-\\underline{\\tilde{y}})^T(\\tilde{\\Phi}\\underline{\\tilde{w}}-\\underline{\\tilde{y}}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linreg(X, yy, alpha):\n",
    "    yy = yy[:, np.newaxis]\n",
    "    # add a column of ones to the X matrix\n",
    "    Phi = np.hstack((X, np.ones((X.shape[0],1))))\n",
    "    # add an identity matrix to the Phi matrix for regularization\n",
    "    # leave the last column as zeros to ignore the bias term\n",
    "    Phi_til = np.vstack((Phi, np.hstack((np.sqrt(alpha)*np.eye(X.shape[1]), np.zeros((X.shape[1],1))))))\n",
    "    # compute the new y vector\n",
    "    yy_til = np.vstack((yy, np.zeros((X.shape[1],1))))\n",
    "    # compute the weights\n",
    "    w = np.linalg.lstsq(Phi_til, yy_til, rcond=None)[0][:,0]\n",
    "    return w[:-1], w[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weighs and bias for the linreg model\n",
    "w_linreg, b_linreg = fit_linreg(X_train, y_train, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct_support_code import fit_linreg_gradopt\n",
    "# compute the weighs and bias for the linreg_gradopt model\n",
    "w_grad, b_grad = fit_linreg_gradopt(X_train, y_train, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(X, yy, ww, bb):\n",
    "    residuals = X @ ww[:, np.newaxis] + bb - yy[:, np.newaxis]\n",
    "    return np.sqrt(residuals.T @ residuals / len(yy))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training linear regression: 0.3567565397204054\n",
      "RMSE for training gradient descent: 0.35675704441316\n",
      "RMSE for validation linear regression: 0.4230521968394691\n",
      "RMSE for validation gradient descent: 0.42305140573952943\n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE for training linear regression: {compute_rmse(X_train, y_train, w_linreg, b_linreg)}')\n",
    "print(f'RMSE for training gradient descent: {compute_rmse(X_train, y_train, w_grad, b_grad)}')\n",
    "print(f'RMSE for validation linear regression: {compute_rmse(X_val, y_val, w_linreg, b_linreg)}')\n",
    "print(f'RMSE for validation gradient descent: {compute_rmse(X_val, y_val, w_grad, b_grad)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct_support_code import logreg_cost, minimize_list\n",
    "#write a function to fit logistc regresion using gradient opt\n",
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20 # number of thresholded classification problems to fit\n",
    "mx = np.max(y_train); mn = np.min(y_train); hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "params = []\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "    # ... fit logistic regression to these labels\n",
    "    params.append(fit_logreg_gradopt(X_train, labels, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_train = []\n",
    "pred_list_val = []\n",
    "\n",
    "#sigmoid function to be used to normalise X\n",
    "def sigmoid_func(x): \n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#utilise the parameters from the model fitted earlier and apply sigmoid on the predictions\n",
    "for i in range(K):\n",
    "    pred_list_train.append(sigmoid_func(X_train @ params[i][0] + params[i][1]))\n",
    "    pred_list_val.append(sigmoid_func(X_val @ params[i][0] + params[i][1]))\n",
    "    \n",
    "X_train_transform = np.vstack(pred_list_train).T\n",
    "X_val_transform = np.vstack(pred_list_val).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit linear regression on the predictions\n",
    "w_train, b_train = fit_linreg(X_train_transform, y_train, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training linear regression: 0.15441150429813472\n",
      "RMSE for training linear regression: 0.2542477297925759\n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE for training linear regression: {compute_rmse(X_train_transform, y_train, w_train, b_train)}')\n",
    "print(f'RMSE for training linear regression: {compute_rmse(X_val_transform, y_val, w_train, b_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting a neural networks with pre-determined weights \n",
    "from ct_support_code import nn_cost\n",
    "def fit_nn(init, X, yy, alpha):\n",
    "    args = (X, yy, alpha)\n",
    "    ww_bar, bb_bar, V_bar, bk_bar = minimize_list(nn_cost, init, args)\n",
    "    return ww_bar, bb_bar, V_bar, bk_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_weights = np.vstack([params[k][0] for k in range(K)])\n",
    "input_biases = np.array([params[k][1] for k in range(K)])\n",
    "init = w_train, b_train, input_weights, input_biases\n",
    "\n",
    "new_params = fit_nn(init, X_train, y_train, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting a neural networks with random weights\n",
    "\n",
    "rand_hidden_weights = np.random.uniform(-1, 1, K)\n",
    "rand_hidden_bias = np.random.uniform(-1, 1)\n",
    "rand_input_weights = np.random.uniform(-1, 1, (K, X_train.shape[1]))\n",
    "rand_input_bias = np.random.uniform(-1, 1, K)\n",
    "rand_init = rand_hidden_weights, rand_hidden_bias, rand_input_weights, rand_input_bias\n",
    "\n",
    "rand_nn_params = fit_nn(rand_init, X_train, y_train, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for train NN: 0.13962174633354246\n",
      "RMSE for val NN: 0.2684062894655103\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "nn_train_predictions = nn_cost(new_params, X_train)\n",
    "nn_val_predictions = nn_cost(new_params, X_val)\n",
    "def nn_rmse(predictions, yy):\n",
    "    residuals = (predictions - yy)[:,np.newaxis]\n",
    "    return np.sqrt(residuals.T @ residuals / len(yy))[0][0]\n",
    "print(f'RMSE for train NN: {nn_rmse(nn_train_predictions, y_train)}')\n",
    "print(f'RMSE for val NN: {nn_rmse(nn_val_predictions, y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for train NN: 0.13930023727216795\n",
      "RMSE for val NN: 0.2719298622850644\n"
     ]
    }
   ],
   "source": [
    "rand_nn_train_predictions = nn_cost(rand_nn_params, X_train)\n",
    "rand_nn_val_predictions = nn_cost(rand_nn_params, X_val)\n",
    "print(f'RMSE for train NN: {nn_rmse(rand_nn_train_predictions, y_train)}')\n",
    "print(f'RMSE for val NN: {nn_rmse(rand_nn_val_predictions, y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_reg(alpha, X_train, y_train, X_val, y_val):\n",
    "    hidden_weights = np.random.uniform(-1, 1, K)\n",
    "    hidden_bias = np.random.uniform(-1, 1)\n",
    "    input_weights = np.random.uniform(-1, 1, (K, X_train.shape[1]))\n",
    "    input_bias = np.random.uniform(-1, 1, K)\n",
    "    init = hidden_weights, hidden_bias, input_weights, input_bias\n",
    "\n",
    "    nn_params = fit_nn(init, X_train, y_train, alpha)\n",
    "    val_predictions = nn_cost(nn_params, X_val)\n",
    "    return nn_rmse(val_predictions, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.array([0,25,50])\n",
    "baseline = np.log(nn_rmse(rand_nn_val_predictions, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_nn_rmse = np.array([train_nn_reg(alpha, X_train, y_train, X_val, y_val) for alpha in alpha_list])\n",
    "alpha_nn_y_vals = baseline - np.log(alpha_nn_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct_support_code import gp_post_par\n",
    "alpha_all = np.arange(0, 50, 0.02)\n",
    "alpha_rest = np.setdiff1d(alpha_all, alpha_list)\n",
    "gp_post_par_resutlts = gp_post_par(alpha_rest, alpha_list, alpha_nn_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def acquisition_function(gp_post_par_resutlts, y_obs):\n",
    "    return stats.norm.cdf((gp_post_par_resutlts[0] - np.max(y_obs))/np.diag(gp_post_par_resutlts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.array([0,25,50])\n",
    "alpha_nn_rmse = alpha_nn_rmse[:3]\n",
    "alpha_nn_y_vals = alpha_nn_y_vals[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.66\n",
      "12.64\n",
      "9.14\n",
      "36.42\n"
     ]
    }
   ],
   "source": [
    "new_alphas = []\n",
    "prob_imp_list = []\n",
    "for i in range(5):\n",
    "    prob_imp = acquisition_function(gp_post_par_resutlts, alpha_nn_y_vals)\n",
    "    prob_imp_list.append(prob_imp[np.argmax(prob_imp)])\n",
    "    new_alpha = alpha_all[np.argmax(prob_imp)]\n",
    "    new_alphas.append(new_alpha)\n",
    "    print(new_alpha)\n",
    "    if i != 4:\n",
    "        alpha_list = np.append(alpha_list, new_alpha)\n",
    "        alpha_nn_rmse = np.append(alpha_nn_rmse, train_nn_reg(new_alpha, X_train, y_train, X_val, y_val))\n",
    "        alpha_nn_y_vals = baseline - np.log(alpha_nn_rmse)\n",
    "        gp_post_par_resutlts = gp_post_par(alpha_rest, alpha_list, alpha_nn_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3113905214879238, 0.07923897635238492, 0.003945606495911536, 3.3341753499797556e-14, 1.7024546985393874e-23]\n",
      "[20.68, 16.66, 12.64, 9.14, 36.42]\n"
     ]
    }
   ],
   "source": [
    "print(prob_imp_list)\n",
    "print(new_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.68 0.3113905214879238\n"
     ]
    }
   ],
   "source": [
    "best_index = np.argmax(prob_imp_list)\n",
    "best_prob_imp = prob_imp_list[best_index]\n",
    "best_alpha = new_alphas[best_index]\n",
    "print(best_alpha, best_prob_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for train NN: 0.12106856533283024\n",
      "RMSE for val NN: 0.26104825630741324\n"
     ]
    }
   ],
   "source": [
    "def get_nn_RMSE(alpha, X_train, y_train, X_val, y_val):\n",
    "    hidden_weights = np.random.uniform(-1, 1, K)\n",
    "    hidden_bias = np.random.uniform(-1, 1)\n",
    "    input_weights = np.random.uniform(-1, 1, (K, X_train.shape[1]))\n",
    "    input_bias = np.random.uniform(-1, 1, K)\n",
    "    init = hidden_weights, hidden_bias, input_weights, input_bias\n",
    "\n",
    "    nn_params = fit_nn(init, X_train, y_train, alpha)\n",
    "    train_predictions = nn_cost(nn_params, X_train)\n",
    "    val_predictions = nn_cost(nn_params, X_val)\n",
    "    print(f'RMSE for train NN: {nn_rmse(train_predictions, y_train)}')\n",
    "    print(f'RMSE for val NN: {nn_rmse(val_predictions, y_val)}')\n",
    "\n",
    "get_nn_RMSE(best_alpha, X_train, y_train, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
